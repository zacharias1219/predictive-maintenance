{"cells":[{"cell_type":"markdown","metadata":{},"source":["# C-MAPSS"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Importing important Library.\n","\n","import pandas as pd  \n","import numpy as np \n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import plotly.express as px\n","%matplotlib inline\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Reading all the \"train_FD00[i].txt\" files as Dataframes.\n","\n","train1=pd.read_csv('train_FD001.txt',sep=\"\\s+\",header=None)\n","train2=pd.read_csv('train_FD002.txt',sep=\"\\s+\",header=None)\n","train3=pd.read_csv('train_FD003.txt',sep=\"\\s+\",header=None)\n","train4=pd.read_csv('train_FD004.txt',sep=\"\\s+\",header=None)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Getting the shapes of all the \"train_FD00[i].txt\" files.\n","\n","print(\"Shape of 'train_FD001.txt' is: \",train1.shape)\n","print(\"Shape of 'train_FD002.txt' is: \",train2.shape)\n","print(\"Shape of 'train_FD003.txt' is: \",train3.shape)\n","print(\"Shape of 'train_FD004.txt' is: \",train4.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying first 5 rows of \"train_FD001.txt\" file.\n","\n","print(\"First 5 rows of 'train_FD001.txt' are: \")\n","train1.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying first 5 rows of \"train_FD002.txt\" file.\n","\n","print(\"First 5 rows of 'train_FD002.txt' are: \")\n","train2.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying first 5 rows of \"train_FD003.txt\" file.\n","\n","print(\"First 5 rows of 'train_FD003.txt' are: \")\n","train3.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying first 5 rows of \"train_FD004.txt\" file.\n","\n","print(\"First 5 rows of 'train_FD004.txt' are: \")\n","train4.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Providing the Feature names.\n","\n","column_names=[\"engine\", \"cycle\", \"setting1\", \"setting2\", \"setting3\", \"sensor1\", \"sensor2\", \"sensor3\", \"sensor4\", \"sensor5\", \"sensor6\", \"sensor7\", \"sensor8\", \"sensor9\", \"sensor10\", \"sensor11\", \"sensor12\", \"sensor13\", \"sensor14\", \"sensor15\", \"sensor16\", \"sensor17\", \"sensor18\", \"sensor19\", \"sensor20\", \"sensor21\"]"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Assigning the Feature names to the corresponding Dataframe.\n","\n","train1.columns=column_names\n","train2.columns=column_names\n","train3.columns=column_names\n","train4.columns=column_names"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying first 5 rows of \"train_FD001.txt\" file after assigning feature names.\n","\n","print(\"First 5 rows of 'train_FD001.txt' are: \")\n","train1.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying first 5 rows of \"train_FD002.txt\" file after assigning feature names.\n","\n","print(\"First 5 rows of 'train_FD002.txt' are: \")\n","train2.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying first 5 rows of \"train_FD003.txt\" file after assigning feature names.\n","\n","print(\"First 5 rows of 'train_FD003.txt' are: \")\n","train3.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying first 5 rows of \"train_FD004.txt\" file after assigning feature names.\n","\n","print(\"First 5 rows of 'train_FD004.txt' are: \")\n","train4.head()"]},{"cell_type":"markdown","metadata":{},"source":["### Where Feature names belongs to:\n","\n","#### 1. Index Names:\n","1.  \"engine\" : Engine No.\n","2.  \"cycle\" : Time, In Cycles\n","#### 2. Setting Names:\n","3.  \"setting1\" : Operation Setting 1\n","4.  \"setting2\" : Operation Setting 2\n","5.  \"setting3\" : Operation Setting 3\n","#### 3. Sensor Names:\n","6.  \"sensor1\" : Fan Inlet Temperature (◦R)\n","7.  \"sensor2\" : LPC Outlet Temperature (◦R)\n","8.  \"sensor3\" : HPC Outlet Temperature (◦R)\n","9.  \"sensor4\" : LPT Outlet Temperature (◦R)\n","10. \"sensor5\" : Fan Inlet Pressure (psia)\n","11. \"sensor6\" : Bypass-Duct Pressure (psia)\n","12. \"sensor7\" : HPC Outlet Pressure (psia)\n","13. \"sensor8\" : Physical Fan Speed (rpm)\n","14. \"sensor9\" : Physical Core Speed (rpm)\n","15. \"sensor10\" : Engine Pressure Ratio(P50/P2)\n","16. \"sensor11\" : HPC Outlet Static Pressure (psia)\n","17. \"sensor12\" : Ratio of Fuel Flow to Ps30 (pps/psia)\n","18. \"sensor13\" : Corrected Fan Speed (rpm)\n","19. \"sensor14\" : Corrected Core Speed (rpm)\n","20. \"sensor15\" : Bypass Ratio\n","21. \"sensor16\" : Burner Fuel-Air Ratio\n","22. \"sensor17\" : Bleed Enthalpy\n","23. \"sensor18\" : Required Fan Speed\n","24. \"sensor19\" : Required Fan Conversion Speed\n","25. \"sensor20\" : High-Pressure Turbines Cool Air Flow\n","26. \"sensor21\" : Low-Pressure Turbines Cool Air Flow"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Information about all the train Dataframes.\n","\n","print(\"Info of 'train_FD001.txt' file is: \\n\")\n","train1.info()\n","print(\"\\nInfo of 'train_FD002.txt' file is: \\n\")\n","train2.info()\n","print(\"\\nInfo of 'train_FD003.txt' file is: \\n\")\n","train3.info()\n","print(\"\\nInfo of 'train_FD004.txt' file is: \\n\")\n","train4.info()"]},{"cell_type":"markdown","metadata":{},"source":["### Observation: All the train Dataframes contains Numeric values in all the features. "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Null Values of all the  tarin Dataframes.\n","\n","print(f\"Null Values of 'train_FD001.txt' file are: {train1.isnull().sum().sum()}\\n\\n{train1.isnull().sum()}\")\n","print(f\"\\nNull Values of 'train_FD002.txt' file are: {train2.isnull().sum().sum()}\\n\\n{train2.isnull().sum()}\")\n","print(f\"\\nNull Values of 'train_FD003.txt' file are: {train3.isnull().sum().sum()}\\n\\n{train3.isnull().sum()}\")\n","print(f\"\\nNull Values of 'train_FD004.txt' file are: {train4.isnull().sum().sum()}\\n\\n{train4.isnull().sum()}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Obervation: There are no null values in any of the columns of any of the train Dataframes."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Checking for the duplicated values in all the train Dataframes.\n","\n","print(f\"Duplicated values in 'train1' Dataframe are: {train1.duplicated().sum()}\")\n","print(f\"\\nDuplicated values in 'train2' Dataframe are: {train1.duplicated().sum()}\")\n","print(f\"\\nDuplicated values in 'train3' Dataframe are: {train1.duplicated().sum()}\")\n","print(f\"\\nDuplicated values in 'train4' Dataframe are: {train1.duplicated().sum()}\")"]},{"cell_type":"markdown","metadata":{},"source":["### Observation: There are no Duplicted values in any of the train Dataframe."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Describing the train1 Dataframe.\n","\n","print(f\"Describing the 'train1' Dataframe: \\n\")\n","train1.describe().T"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Describing the train2 Dataframe.\n","\n","print(f\"Describing the 'train2' Dataframe: \\n\")\n","train2.describe().T"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Describing the train3 Dataframe.\n","\n","print(f\"Describing the 'train3' Dataframe: \\n\")\n","train3.describe().T"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Describing the train4 Dataframe.\n","\n","print(f\"Describing the 'train4' Dataframe: \\n\")\n","train4.describe().T"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Unique categories of each feature in train Dataframes.\n","\n","print(f\"Unique categories of each feature in train1 Dataframe: {len(train1.columns)}\\n\\n{train1.nunique()}\")\n","print(f\"\\nUnique categories of each feature in train2 Dataframe: {len(train2.columns)}\\n\\n{train2.nunique()}\")\n","print(f\"\\nUnique categories of each feature in train3 Dataframe: {len(train3.columns)}\\n\\n{train3.nunique()}\")\n","print(f\"\\nUnique categories of each feature in train4 Dataframe: {len(train4.columns)}\\n\\n{train4.nunique()}\")"]},{"cell_type":"markdown","metadata":{},"source":["#### Observation: Some of the feature's unique categories are 1. Like In 'train1' Dataframe, 'setting3', 'sensor1', 'sensor5', 'sensor10', 'sensor16', 'sensor18' and 'sensor19' and In 'train3' Dataframe, 'setting3', 'sensor1', 'sensor5', 'sensor16', 'sensor18', 'sensor19'. These features are useless as they contains only one category so we have to remove these selected features from \"train1\" and \"train3\" dataframes."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Removing Useless features from all selected Dataframes.\n","\n","train1=train1.drop(columns=[\"setting3\", \"sensor1\", \"sensor5\", \"sensor10\", \"sensor16\", \"sensor18\", \"sensor19\"])\n","train3=train3.drop(columns=[\"setting3\", \"sensor1\", \"sensor5\", \"sensor16\", \"sensor18\", \"sensor19\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Checking remaining Features all Dataframes.\n","\n","print(f\"Remaining features of 'train1' Dataframe: {len(train1.columns)}\\n\\n{train1.columns}\")\n","print(f\"\\nRemaining features of 'train2' Dataframe: {len(train2.columns)}\\n\\n{train2.columns}\")\n","print(f\"\\nRemaining features of 'train3' Dataframe: {len(train3.columns)}\\n\\n{train3.columns}\")\n","print(f\"\\nRemaining features of 'train4' Dataframe: {len(train4.columns)}\\n\\n{train4.columns}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying first 5 rows of all the train Dataframes after removing useless features from \"train1\" and \"train3\" Dataframes.\n","\n","display(\n","'''First 5 rows of 'train_FD001.txt' are: ''',  \n","train1.head(),\n","    \n","'''First 5 rows of 'train_FD002.txt' are: ''',\n","train2.head(),\n","    \n","'''First 5 rows of 'train_FD003.txt' are: ''',\n","train3.head(),\n","    \n","'''First 5 rows of 'train_FD004.txt' are: ''',\n","train4.head()\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Unique categories of engines in all the train Dataframes.\n","\n","print(f\"Unique categories of engines in 'train1' Dataframe are: {len(train1['engine'].unique())} \\n\\n{train1['engine'].unique()}\")\n","print(f\"\\nUnique categories of engines in 'train2' Dataframe are: {len(train2['engine'].unique())} \\n\\n{train2['engine'].unique()}\")\n","print(f\"\\nUnique categories of engines in 'train3' Dataframe are: {len(train3['engine'].unique())} \\n\\n{train3['engine'].unique()}\")\n","print(f\"\\nUnique categories of engines in 'train4' Dataframe are: {len(train4['engine'].unique())} \\n\\n{train4['engine'].unique()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Max cycle counts of engines in all train Dataframes.\n","\n","display(\n","'''Max cycle counts of engines in 'train1' Dataframe are: ''',  \n","train1[[\"engine\", \"cycle\"]].groupby('cycle').max(),\n","    \n","'''Max cycle counts of engines in 'train2' Dataframe are: ''',\n","train2[[\"engine\", \"cycle\"]].groupby('cycle').max(),\n","    \n","'''Max cycle counts of engines in 'train3' Dataframe are: ''',\n","train3[[\"engine\", \"cycle\"]].groupby('cycle').max(),\n","    \n","'''Max cycle counts of engines in 'train4' Dataframe are: ''',\n","train4[[\"engine\", \"cycle\"]].groupby('cycle').max()\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Finding highest cycle count in a sinlge engine in 'train1' dataframe:  all train Dataframes.\n","\n","a=train1[\"cycle\"].max()\n","print(f\"highest cycle count in a sinlge Engine in 'train1' Dataframe is: {a}\")\n","\n","b=train2[\"cycle\"].max()\n","print(f\"highest cycle count in a sinlge Engine in 'train2' Dataframe is: {b}\")\n","\n","c=train3[\"cycle\"].max()\n","print(f\"highest cycle count in a sinlge Engine in 'train3' Dataframe is: {c}\")\n","\n","d=train4[\"cycle\"].max()\n","print(f\"highest cycle count in a sinlge Engine in 'train4' Dataframe is: {d}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Defining the function to plot barplots of train Dataframes. \n","\n","def bar_plot1(df, col_names):\n","    max_time_cycles=df[col_names].groupby('engine').max()\n","    plt.figure(figsize=(20,50))\n","    ax=max_time_cycles['cycle'].plot(kind='barh',width=0.8, stacked=True,align='center')\n","    plt.title('Turbofan Engines LifeTime',fontweight='bold',size=30)\n","    plt.xlabel('Time, In Cycles',fontweight='bold',size=20)\n","    plt.ylabel('unit',fontweight='bold',size=20)\n","    plt.show()\n","\n","def bar_plot2(df, col_names):\n","    max_time_cycles=df[col_names].groupby('engine').max()\n","    plt.figure(figsize=(20,100))\n","    ax=max_time_cycles['cycle'].plot(kind='barh',width=0.8, stacked=True,align='center')\n","    plt.title('Turbofan Engines LifeTime',fontweight='bold',size=30)\n","    plt.xlabel('Time, In Cycles',fontweight='bold',size=20)\n","    plt.ylabel('unit',fontweight='bold',size=20)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''\n","## Barplot of 'train1' Dataframe.\n","\n","bar_plot1(train1,train1.columns)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''\n","## Barplot of 'train2' Dataframe.\n","\n","bar_plot2(train2,train2.columns)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''\n","## Barplot of 'train3' Dataframe.\n","\n","bar_plot1(train3,train3.columns)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''\n","## Barplot of 'train4' Dataframe.\n","\n","bar_plot2(train4,train4.columns)\n","'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating the bar plot\n","\n","plt.figure(figsize=(15, 8))\n","plt.bar(train1['engine'],train1['cycle'])\n","\n","# Adding labels and title\n","\n","plt.xlabel('Engine Number')\n","plt.ylabel('Cycle Count')\n","plt.title('Bar Plot of Max Cycle counts of each Engine in \"train1\" Dataframe')\n","\n","# Display the plot\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Finding engine Number of highest cycle count.\n","\n","df1=train1.groupby('engine')[['cycle']].max()\n","df1[df1['cycle'] == 362]"]},{"cell_type":"markdown","metadata":{},"source":["#### Observation: With the bar-plot and above results we observe that In 'train1' dataframe, 'Engine Number 69' have highest 'Cycle Count' among other Engine numbers."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating the bar plot\n","\n","plt.figure(figsize=(20, 8))\n","plt.bar(train2['engine'],train2['cycle'])\n","\n","# Adding labels and title\n","\n","plt.xlabel('Engine Number')\n","plt.ylabel('Cycle Count')\n","plt.title('Bar Plot of Max Cycle counts of each Engine in \"train2\" Dataframe')\n","\n","# Display the plot\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Finding engine Number of highest cycle count.\n","\n","df2=train2.groupby('engine')[['cycle']].max()\n","df2[df2['cycle'] == 378]"]},{"cell_type":"markdown","metadata":{},"source":["#### Observation: With the bar-plot and above results we observe that In 'train2' dataframe, 'Engine Number 112' have highest 'Cycle Count' among other Engine numbers."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating the bar plot\n","\n","plt.figure(figsize=(15, 8))\n","plt.bar(train3['engine'],train3['cycle'])\n","\n","# Adding labels and title\n","\n","plt.xlabel('Engine Number')\n","plt.ylabel('Cycle Count')\n","plt.title('Bar Plot of Max Cycle counts of each Engine in \"train3\" Dataframe')\n","\n","# Display the plot\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Finding engine Number of highest cycle count.\n","\n","df3=train3.groupby('engine')[['cycle']].max()\n","df3[df3['cycle'] == 525]"]},{"cell_type":"markdown","metadata":{},"source":["#### Observation: With the bar-plot and above results we observe that In 'train3' dataframe, 'Engine Number 55' have highest 'Cycle Count' among other Engine numbers."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Creating the bar plot\n","\n","plt.figure(figsize=(20, 8))\n","plt.bar(train4['engine'],train4['cycle'])\n","\n","# Adding labels and title\n","\n","plt.xlabel('Engine Number')\n","plt.ylabel('Cycle Count')\n","plt.title('Bar Plot of Max Cycle counts of each Engine in \"train4\" Dataframe')\n","\n","# Display the plot\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Finding engine Number of highest cycle count.\n","\n","df4=train4.groupby('engine')[['cycle']].max()\n","df4[df4['cycle'] == 543]"]},{"cell_type":"markdown","metadata":{},"source":["#### Observation: With the bar-plot and above results we observe that In 'train4' dataframe, 'Engine Number 118' have highest 'Cycle Count' among other Engine numbers."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Defining the function to calculate the RUL.\n","\n","def Calculate_RUL(df):\n","    max_cycles = df.groupby('engine')['cycle'].max()\n","    merged = df.merge(max_cycles.to_frame(name='max_time_cycle'), left_on='engine',right_index=True)\n","    merged[\"RUL\"] = merged[\"max_time_cycle\"] - merged['cycle']\n","    merged = merged.drop(\"max_time_cycle\", axis=1)\n","    return merged"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Merging the calculated RUL in the train Dataframes.\n","\n","train1=Calculate_RUL(train1)\n","train2=Calculate_RUL(train2)\n","train3=Calculate_RUL(train3)\n","train4=Calculate_RUL(train4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Checking remaining Features all train Dataframes after adding RUL.\n","\n","print(f\"Remaining features of 'train1' Dataframe: {len(train1.columns)}\\n\\n{train1.columns}\")\n","print(f\"\\nRemaining features of 'train2' Dataframe: {len(train2.columns)}\\n\\n{train2.columns}\")\n","print(f\"\\nRemaining features of 'train3' Dataframe: {len(train3.columns)}\\n\\n{train3.columns}\")\n","print(f\"\\nRemaining features of 'train4' Dataframe: {len(train4.columns)}\\n\\n{train4.columns}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying first 5 rows of all the train Dataframes after adding RUL in train Dataframes.\n","\n","display(\n","'''First 5 rows of 'train_FD001.txt' are: ''',  \n","train1.head(),\n","    \n","'''First 5 rows of 'train_FD002.txt' are: ''',\n","train2.head(),\n","    \n","'''First 5 rows of 'train_FD003.txt' are: ''',\n","train3.head(),\n","    \n","'''First 5 rows of 'train_FD004.txt' are: ''',\n","train4.head()\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Defining a function to plot signal plots.\n","\n","def plot_signal(df,col):\n","    plt.figure(figsize=(13,5))\n","    for i in df['engine'].unique():\n","        if (i % 10 == 0):   #For a better visualisation, we plot the sensors signals of 20 units only\n","            plt.plot('RUL', col, data=df[df['engine']==i].rolling(10).mean())\n","\n","    plt.xlim(250, 0)  # reverse the x-axis so RUL counts down to zero\n","    plt.xticks(np.arange(0, 300, 25))\n","    plt.ylabel(col)\n","    plt.xlabel('Remaining Useful Life')\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Removing useless features from 'train1' Dataframe for plotting signal plot.\n","\n","cols1=train1.drop(columns=['engine', 'cycle', 'RUL'])\n","cols1=cols1.columns\n","for col1 in cols1:\n","    plot_signal(train1,col1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Removing useless features from 'train2' Dataframe for plotting signal plot.\n","\n","cols2=train2.drop(columns=['engine', 'cycle', 'RUL'])\n","cols2=cols2.columns\n","for col2 in cols2:\n","    plot_signal(train2,col2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Removing useless features from 'train3' Dataframe for plotting signal plot.\n","\n","cols3=train3.drop(columns=['engine', 'cycle', 'RUL'])\n","cols3=cols3.columns\n","for col3 in cols3:\n","    plot_signal(train3,col3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Removing useless features from 'train4' Dataframe for plotting signal plot.\n","\n","cols4=train4.drop(columns=['engine', 'cycle', 'RUL'])\n","cols4=cols4.columns\n","for col4 in cols4:\n","    plot_signal(train4,col4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying correlations of all train Dataframes.\n","\n","display(\n","    '''train1 Dataframe's Correlations are:''',\n","    train1.corr(),\n","    '''train2 Dataframe's Correlations are:''',\n","    train2.corr(),\n","    '''train3 Dataframe's Correlations are:''',\n","    train3.corr(),\n","    '''train4 Dataframe's Correlations are:''',\n","    train4.corr()\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Defining the function to plot heatmap.\n","\n","def heat_map(df):\n","    sns.heatmap(df.corr(),annot=True,linewidths=0.2)\n","    fig=plt.gcf()\n","    fig.set_size_inches(20,20)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## 'train1' Dataframe heatmap.\n","\n","heat_map(train1)"]},{"cell_type":"markdown","metadata":{},"source":["### Observation: 'engine', 'setting1', 'setting2', 'sensor6' are least correalted with any other features."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## 'train2' Dataframe heatmap.\n","\n","heat_map(train2)"]},{"cell_type":"markdown","metadata":{},"source":["### Observation: 'engine', 'cycle', 'RUL' are least correalted with any other features."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## 'train3' Dataframe heatmap.\n","\n","heat_map(train3)"]},{"cell_type":"markdown","metadata":{},"source":["### Observation: 'engine', 'setting1', 'setting2', 'sensor6' are least correalted with any other features."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## 'train4' Dataframe heatmap.\n","\n","heat_map(train4)"]},{"cell_type":"markdown","metadata":{},"source":["### Observation: 'engine', 'cycle', 'RUL' are least correalted with any other features."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Defining the function for boxplots.\n","\n","def box_plot(df,col):\n","    fig=px.box(df,x=col)\n","    fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Box plots of sensors of 'train1' Dataframe after removing least correlated sensors.\n","\n","sensors1=train1.drop(columns=['engine', 'cycle', 'setting1', 'setting2', 'sensor6', 'RUL'])\n","sensors1=sensors1.columns\n","\n","for sensor1 in sensors1:\n","    box_plot(train1,sensor1)"]},{"cell_type":"markdown","metadata":{},"source":["## Observation: Columns 'engine', 'cycle', 'setting1', 'setting2', 'sensor6', 'RUL' are useless in 'train1' for model so we will drop them while doing train-test spliting."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Box plots of sensors of 'train2' Dataframe after removing least correlated sensors.\n","\n","sensors2=train2.drop(columns=['engine', 'setting1', 'setting2', 'setting3', 'sensor13', 'sensor16', 'sensor19', 'cycle', 'RUL'])\n","sensors2=sensors2.columns\n","\n","for sensor2 in sensors2:\n","    box_plot(train2,sensor2)"]},{"cell_type":"markdown","metadata":{},"source":["## Observation: Columns 'engine', 'setting1', 'setting2', 'setting3', 'sensor13', 'sensor16', 'sensor19', 'cycle', 'RUL' are useless in 'train2' for model so we will drop them while doing train-test spliting."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Box plots of sensors of 'train3' Dataframe after removing least correlated sensors.\n","\n","sensors3=train3.drop(columns=['engine', 'cycle', 'setting1', 'setting2', 'sensor6', 'sensor6', 'RUL'])\n","sensors3=sensors3.columns\n","\n","for sensor3 in sensors3:\n","    box_plot(train3,sensor3)"]},{"cell_type":"markdown","metadata":{},"source":["## Observation: Columns 'engine', 'cycle', 'setting1', 'setting2', 'sensor6', 'sensor10', 'RUL' are useless in 'train3' for model so we will drop them while doing train-test spliting."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Box plots of sensors of 'train4' Dataframe after removing least correlated sensors.\n","\n","sensors4=train4.drop(columns=['engine', 'setting1', 'setting2', 'setting3', 'sensor13', 'sensor16', 'sensor19', 'cycle', 'RUL'])\n","sensors4=sensors4.columns\n","\n","for sensor4 in sensors4:\n","    box_plot(train4,sensor4)"]},{"cell_type":"markdown","metadata":{},"source":["## Observation: Columns 'engine', 'setting1', 'setting2', 'setting3', 'sensor13', 'sensor16', 'sensor19', 'cycle', 'RUL' are useless in 'train4' for model so we will drop them while doing train-test spliting."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Importing libraries for model training.\n","\n","from sklearn.model_selection import train_test_split"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Splitting 'train1' Dataframe for model training.\n","\n","X1=train1.drop(columns=['engine', 'cycle', 'setting1', 'setting2', 'sensor6', 'RUL'])\n","y1=train1['RUL']\n","X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.20, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Splitting 'train2' Dataframe for model training.\n","\n","X2=train2.drop(columns=['engine', 'setting1', 'setting2', 'setting3', 'sensor13', 'sensor16', 'sensor19', 'cycle', 'RUL'])\n","y2=train2['RUL']\n","X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.20, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Splitting 'train3' Dataframe for model training.\n","\n","X3=train3.drop(columns=['engine', 'cycle', 'setting1', 'setting2', 'sensor6', 'sensor10', 'RUL'])\n","y3=train3['RUL']\n","X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.20, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Splitting 'train4' Dataframe for model training.\n","\n","X4=train4.drop(columns=['engine', 'setting1', 'setting2', 'setting3', 'sensor13', 'sensor16', 'sensor19', 'cycle', 'RUL'])\n","y4=train4['RUL']\n","X_train4, X_test4, y_train4, y_test4 = train_test_split(X4, y4, test_size=0.20, random_state=42)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Importing RUL_FD001, RUL_FD002, RUL_FD003 and RUL_FD004.\n","\n","rul1=pd.read_csv(\"RUL_FD001.txt\",header=None, names=[\"RUL\"])\n","rul2=pd.read_csv(\"RUL_FD002.txt\",header=None, names=[\"RUL\"])\n","rul3=pd.read_csv(\"RUL_FD003.txt\",header=None, names=[\"RUL\"])\n","rul4=pd.read_csv(\"RUL_FD004.txt\",header=None, names=[\"RUL\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["rul1"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Importing test datasets.\n","\n","test1=pd.read_csv('test_FD001.txt',sep=\"\\s+\",header=None)\n","test2=pd.read_csv('test_FD002.txt',sep=\"\\s+\",header=None)\n","test3=pd.read_csv('test_FD003.txt',sep=\"\\s+\",header=None)\n","test4=pd.read_csv('test_FD004.txt',sep=\"\\s+\",header=None)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Assigning the Feature names to the corresponding Dataframe.\n","\n","test1.columns=column_names\n","test2.columns=column_names\n","test3.columns=column_names\n","test4.columns=column_names"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Importing min-max scaler to scale all the train Dataframes.\n","\n","from sklearn.preprocessing import MinMaxScaler\n","scaler = MinMaxScaler()\n","\n","from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Defining the function to calculate mse, emse, r2 and mae.\n","\n","from sklearn.model_selection import cross_val_score\n","\n","def prediction( model, scaled_test, y_test):\n","    \n","    # Make predictions\n","    y_pred = model.predict(scaled_test)\n","    \n","    # Mean Squared Error (MSE)\n","    mse = mean_squared_error(y_test, y_pred) \n","    print(\"MSE:\", mse)\n","    # MSE measures the average squared difference between actual and predicted values. Lower values are better.\n","    \n","    # Root Mean Squared Error (RMSE)\n","    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n","    print(\"RMSE:\", rmse)\n","    # RMSE is the square root of MSE. Measures predictive accuracy in units of the variable. Lower is better.\n","    \n","    # R-squared (R2) \n","    r2 = r2_score(y_test, y_pred)\n","    print(\"R-squared:\", r2)\n","    # R2 measures proportion of variance in actual data explained by the prediction. Values range 0 to 1. Higher is better. \n","    \n","    # Mean Absolute Error (MAE)\n","    mae = mean_absolute_error(y_test, y_pred)  \n","    print(\"MAE:\", mae)\n","    # MAE measures average absolute difference between actual and predicted values. Lower values are better.\n","\n","    return y_pred"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Scaling X_train1 and X_test1\n","\n","scaled_train1=scaler.fit_transform(X_train1)\n","scaled_test1=scaler.fit_transform(X_test1)\n","\n","## Conserve only the last occurence of each unit to match the length of test1\n","\n","X_valid1 = test1.groupby('engine').last().reset_index().drop(columns=[\"engine\", \"cycle\", \"setting1\", \"setting2\", \"setting3\"])\n","\n","X_valid1.drop(columns=['sensor1','sensor5','sensor6','sensor10','sensor16','sensor18','sensor19'], inplace=True)\n","\n","## scaling X_valid\n","\n","scaled_X_valid1=scaler.fit_transform(X_valid1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Boxplots of X_train1 before scaling.\n","\n","plt.subplots(figsize=(15,5))\n","sns.boxplot(data=X_train1)\n","plt.title(\"X_train1 Before Scaling\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Boxplots of X_train1 after scaling.\n","\n","plt.subplots(figsize=(15,5))\n","sns.boxplot(data=scaled_train1)\n","plt.title(\"X_train1 After Scaling\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''X_valid1'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying the shapes of FD001.\n","\n","print(f\"X_train1: {X_train1.shape}\")\n","print(f\"X_test1: {X_test1.shape}\")\n","print(f\"y_train1: {y_train1.shape}\")\n","print(f\"y_test1: {y_test1.shape}\")\n","print(f\"X_valid1: {X_valid1.shape}\")\n","print(f\"y_valid1: {rul1.shape}\")\n","\n","print(f\"scaled_train1: {scaled_X_valid1.shape}\")\n","print(f\"scaled_test1: {scaled_X_valid1.shape}\")\n","print(f\"scaled_X_valid1: {scaled_X_valid1.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Scaling X_train2 and X_test2\n","\n","scaled_train2=scaler.fit_transform(X_train2)\n","scaled_test2=scaler.fit_transform(X_test2)\n","\n","## Conserve only the last occurence of each unit to match the length of test2\n","\n","X_valid2 = test2.groupby('engine').last().reset_index().drop(columns=[\"engine\", \"cycle\", \"setting1\", \"setting2\", \"setting3\"])\n","\n","X_valid2.drop(columns=['sensor13','sensor16', 'sensor19'], inplace=True)\n","\n","## scaling X_valid\n","\n","scaled_X_valid2=scaler.fit_transform(X_valid2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Boxplots of X_train2 before scaling.\n","\n","plt.subplots(figsize=(15,5))\n","sns.boxplot(data=X_train2)\n","plt.title(\"X_train2 Before Scaling\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Boxplots of X_train2 after scaling.\n","\n","plt.subplots(figsize=(15,5))\n","sns.boxplot(data=scaled_train2)\n","plt.title(\"X_train2 After Scaling\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''X_valid2'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying the shapes of FD002.\n","\n","print(f\"X_train2: {X_train2.shape}\")\n","print(f\"X_test2: {X_test2.shape}\")\n","print(f\"y_train2: {y_train2.shape}\")\n","print(f\"y_test2: {y_test2.shape}\")\n","print(f\"X_valid2: {X_valid2.shape}\")\n","print(f\"y_valid2: {rul2.shape}\")\n","\n","print(f\"scaled_train2: {scaled_X_valid2.shape}\")\n","print(f\"scaled_test2: {scaled_X_valid2.shape}\")\n","print(f\"scaled_X_valid2: {scaled_X_valid2.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Scaling X_train3 and X_test3\n","\n","scaled_train3=scaler.fit_transform(X_train3)\n","scaled_test3=scaler.fit_transform(X_test3)\n","\n","## Conserve only the last occurence of each unit to match the length of test3\n","\n","X_valid3 = test3.groupby('engine').last().reset_index().drop(columns=[\"engine\", \"cycle\", \"setting1\", \"setting2\", \"setting3\"])\n","\n","X_valid3.drop(columns=['sensor1','sensor5','sensor6', 'sensor10', 'sensor16','sensor18','sensor19'], inplace=True)\n","\n","## scaling X_valid\n","\n","scaled_X_valid3=scaler.fit_transform(X_valid3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Boxplots of X_train3 before scaling.\n","\n","plt.subplots(figsize=(15,5))\n","sns.boxplot(data=X_train3)\n","plt.title(\"X_train3 Before Scaling\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Boxplots of X_train3 after scaling.\n","\n","plt.subplots(figsize=(15,5))\n","sns.boxplot(data=scaled_train3)\n","plt.title(\"X_train3 After Scaling\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''X_valid3'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying the shapes of FD003.\n","\n","print(f\"X_train3: {X_train3.shape}\")\n","print(f\"X_test3: {X_test3.shape}\")\n","print(f\"y_train3: {y_train3.shape}\")\n","print(f\"y_test3: {y_test3.shape}\")\n","print(f\"X_valid3: {X_valid3.shape}\")\n","print(f\"y_valid3: {rul3.shape}\")\n","\n","print(f\"scaled_train3: {scaled_X_valid3.shape}\")\n","print(f\"scaled_test3: {scaled_X_valid3.shape}\")\n","print(f\"scaled_X_valid3: {scaled_X_valid3.shape}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Scaling X_train4 and X_test4\n","\n","scaled_train4=scaler.fit_transform(X_train4)\n","scaled_test4=scaler.fit_transform(X_test4)\n","\n","## Conserve only the last occurence of each unit to match the length of test4\n","\n","X_valid4 = test4.groupby('engine').last().reset_index().drop(columns=[\"engine\", \"cycle\", \"setting1\", \"setting2\", \"setting3\"])\n","\n","X_valid4.drop(columns=['sensor13','sensor16', 'sensor19'], inplace=True)\n","\n","## scaling X_valid\n","\n","scaled_X_valid4=scaler.fit_transform(X_valid4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Boxplots of X_train4 before scaling.\n","\n","plt.subplots(figsize=(15,5))\n","sns.boxplot(data=X_train4)\n","plt.title(\"X_train4 Before Scaling\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Boxplots of X_train4 after scaling.\n","\n","plt.subplots(figsize=(15,5))\n","sns.boxplot(data=scaled_train4)\n","plt.title(\"X_train4 After Scaling\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["'''X_valid4'''"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Displaying the shapes of FD004.\n","\n","print(f\"X_train4: {X_train4.shape}\")\n","print(f\"X_test4: {X_test4.shape}\")\n","print(f\"y_train4: {y_train4.shape}\")\n","print(f\"y_test4: {y_test4.shape}\")\n","print(f\"X_valid4: {X_valid4.shape}\")\n","print(f\"y_valid4: {rul4.shape}\")\n","\n","print(f\"scaled_train4: {scaled_X_valid4.shape}\")\n","print(f\"scaled_test4: {scaled_X_valid4.shape}\")\n","print(f\"scaled_X_valid4: {scaled_X_valid4.shape}\")"]},{"cell_type":"markdown","metadata":{},"source":["# Model Training"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Defining function to plot real data and the predicted one to make some comparison.\n","\n","def plot_predActual(y_test, y_pred):\n","\n","    indices = np.arange(len(y_pred))\n","    wth= 0.6\n","    plt.figure(figsize=(70,30))\n","    true_values = [int(x) for x in y_test.values]\n","    predicted_values = list(y_pred)\n","\n","    plt.bar(indices, true_values, width=wth,color='b', label='True RUL')\n","    plt.bar([i for i in indices], predicted_values, width=0.5*wth, color='r', alpha=0.7, label='Predicted RUL')\n","\n","    plt.legend(prop={'size': 40})\n","    plt.tick_params(labelsize=40)\n","\n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Linear Regression"]},{"cell_type":"markdown","metadata":{},"source":["#### \"FD001\" "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","linreg=LinearRegression()\n","linreg.fit(scaled_train1,y_train1)\n","\n","## predict and evaluate\n","\n","print(f\"Linear-Regression on FD001-test dataset:\\n\")\n","prediction(linreg, scaled_test1, y_test1)\n","\n","print(f\"\\nLinear-Regression on FD001-train dataset:\\n\")\n","prediction(linreg, scaled_train1, y_train1)\n","\n","print(f\"\\nLinear-Regression on FD001-validation dataset:\\n\")\n","lr_y_pred1=prediction(linreg, scaled_X_valid1, rul1)\n","\n","lr_rul1=rul1.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(lr_rul1, lr_y_pred1)"]},{"cell_type":"markdown","metadata":{},"source":["#### \"FD002\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["linreg.fit(scaled_train2,y_train2)\n","\n","## predict and evaluate\n","\n","print(f\"Linear-Regression on FD002-test dataset:\\n\")\n","prediction(linreg, scaled_test2, y_test2)\n","\n","print(f\"\\nLinear-Regression on FD002-train dataset:\\n\")\n","prediction(linreg, scaled_train2, y_train2)\n","\n","print(f\"\\nLinear-Regression on FD002-validation dataset:\\n\")\n","lr_y_pred2=prediction(linreg, scaled_X_valid2, rul2)\n","\n","lr_rul2=rul2.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(lr_rul2, lr_y_pred2)"]},{"cell_type":"markdown","metadata":{},"source":["#### \"FD003\" "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["linreg.fit(scaled_train3,y_train3)\n","\n","## predict and evaluate\n","\n","print(f\"Linear-Regression on FD003-test dataset:\\n\")\n","prediction(linreg, scaled_test3, y_test3)\n","\n","print(f\"\\nLinear-Regression on FD003-train dataset:\\n\")\n","prediction(linreg, scaled_train3, y_train3)\n","\n","print(f\"\\nLinear-Regression on FD003-validation dataset:\\n\")\n","lr_y_pred3=prediction(linreg, scaled_X_valid3, rul3)\n","\n","lr_rul3=rul3.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(lr_rul3, lr_y_pred3)"]},{"cell_type":"markdown","metadata":{},"source":["#### \"FD004\" "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["linreg.fit(scaled_train4,y_train4)\n","\n","## predict and evaluate\n","\n","print(f\"Linear-Regression on FD004-test dataet:\\n\")\n","prediction(linreg, scaled_test4, y_test4)\n","\n","print(f\"\\nLinear-Regression on FD004-train dataset:\\n\")\n","prediction(linreg, scaled_train4, y_train4)\n","\n","print(f\"\\nLinear-Regression on FD004-validation dataset:\\n\")\n","lr_y_pred4=prediction(linreg, scaled_X_valid4, rul4)\n","\n","lr_rul4=rul4.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(lr_rul4, lr_y_pred4)"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Ridge Regression"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD001'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Importing ridgeCV.\n","\n","from sklearn.linear_model import RidgeCV\n","\n","alpha_values=[1e-15, 1e-10, 1e-8, 1e-4, 1e-3, 1e-2, 1.7, 2.5, 4.2, 5.0, 6.1, 8.8, 10.2, 12.4, 15.0, 18.0, 20.0]\n","ridge = RidgeCV(alphas=alpha_values, cv=5)\n","\n","## Fitting the model.\n","ridge.fit(scaled_train1, y_train1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["#ridge.fit(scaled_train1,y_train1)\n","\n","## predict and evaluate\n","\n","print(f\"Ridge-Regression on FD001-test dataset:\\n\")\n","prediction(ridge, scaled_test1, y_test1)\n","\n","print(f\"\\nRidge-Regression on FD001-train dataset:\\n\")\n","prediction(ridge, scaled_train1, y_train1)\n","\n","print(f\"\\nRidge-Regression on FD001-validation dataset:\\n\")\n","ridge_y_pred1=prediction(ridge, scaled_X_valid1, rul1)\n","\n","ridge_rul1=rul1.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(ridge_rul1, ridge_y_pred1)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD002'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Fitting the model.\n","\n","ridge.fit(scaled_train2, y_train2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Ridge-Regression on FD002-test dataset:\\n\")\n","prediction(ridge, scaled_test2, y_test2)\n","\n","print(f\"\\nRidge-Regression on FD002-train dataset:\\n\")\n","prediction(ridge, scaled_train2, y_train2)\n","\n","print(f\"\\nRidge-Regression on FD002-validation dataset:\\n\")\n","ridge_y_pred2=prediction(ridge, scaled_X_valid2, rul2)\n","\n","ridge_rul2=rul2.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(ridge_rul2, ridge_y_pred2)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD003'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Fitting the model.\n","\n","ridge.fit(scaled_train3, y_train3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Ridge-Regression on FD003-test dataset:\\n\")\n","prediction(ridge, scaled_test3, y_test3)\n","\n","print(f\"\\nRidge-Regression on FD003-train dataset:\\n\")\n","prediction(ridge, scaled_train3, y_train3)\n","\n","print(f\"\\nRidge-Regression on FD003-validation dataset:\\n\")\n","ridge_y_pred3=prediction(ridge, scaled_X_valid3, rul3)\n","\n","ridge_rul3=rul3.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(ridge_rul3, ridge_y_pred3)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD004'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Fitting the model.\n","\n","ridge.fit(scaled_train4, y_train4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Ridge-Regression on FD004-test dataset:\\n\")\n","prediction(ridge, scaled_test4, y_test4)\n","\n","print(f\"\\nRidge-Regression on FD004-train dataset:\\n\")\n","prediction(ridge, scaled_train4, y_train4)\n","\n","print(f\"\\nRidge-Regression on FD004-validation dataset:\\n\")\n","ridge_y_pred4=prediction(ridge, scaled_X_valid4, rul4)\n","\n","ridge_rul4=rul4.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(ridge_rul4, ridge_y_pred4)"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Lasso Regression"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD001'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Importing ridgeCV.\n","\n","from sklearn.linear_model import LassoCV\n","\n","lasso = LassoCV(alphas=alpha_values, cv=5)\n","\n","## Fitting the model.\n","lasso.fit(scaled_train1, y_train1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Lasso-Regression on FD001-test dataset:\\n\")\n","prediction(lasso, scaled_test1, y_test1)\n","\n","print(f\"\\nLasso-Regression on FD001-train dataset:\\n\")\n","prediction(lasso, scaled_train1, y_train1)\n","\n","print(f\"\\nLasso-Regression on FD001-validation dataset:\\n\")\n","lasso_y_pred1=prediction(lasso, scaled_X_valid1, rul1)\n","\n","lasso_rul1=rul1.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(lasso_rul1, lasso_y_pred1)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD002'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Fitting the model.\n","\n","lasso.fit(scaled_train2, y_train2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Lasso-Regression on FD002-test dataset:\\n\")\n","prediction(lasso, scaled_test2, y_test2)\n","\n","print(f\"\\nLasso-Regression on FD002-train dataset:\\n\")\n","prediction(lasso, scaled_train2, y_train2)\n","\n","print(f\"\\nLasso-Regression on FD002-validation dataset:\\n\")\n","lasso_y_pred2=prediction(lasso, scaled_X_valid2, rul2)\n","\n","lasso_rul2=rul2.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(lasso_rul2, lasso_y_pred2)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD003'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Fitting the model.\n","\n","lasso.fit(scaled_train3, y_train3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Lasso-Regression on FD003-test dataset:\\n\")\n","prediction(lasso, scaled_test3, y_test3)\n","\n","print(f\"\\nLasso-Regression on FD003-train dataset:\\n\")\n","prediction(lasso, scaled_train3, y_train3)\n","\n","print(f\"\\nLasso-Regression on FD003-validation dataset:\\n\")\n","lasso_y_pred3=prediction(lasso, scaled_X_valid3, rul3)\n","\n","lasso_rul3=rul3.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(lasso_rul3, lasso_y_pred3)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD004'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Fitting the model.\n","\n","lasso.fit(scaled_train4, y_train4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Lasso-Regression on FD004-test dataset:\\n\")\n","prediction(lasso, scaled_test4, y_test4)\n","\n","print(f\"\\nLasso-Regression on FD004-train dataset:\\n\")\n","prediction(lasso, scaled_train4, y_train4)\n","\n","print(f\"\\nLasso-Regression on FD004-validation dataset:\\n\")\n","lasso_y_pred4=prediction(lasso, scaled_X_valid4, rul4)\n","\n","lasso_rul4=rul4.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(lasso_rul4, lasso_y_pred4)"]},{"cell_type":"markdown","metadata":{},"source":["## 4. Random Forest Regressor"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD001'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.model_selection import GridSearchCV\n","from sklearn.ensemble import RandomForestRegressor\n","\n","estimator = RandomForestRegressor()\n","param_grid = {\n","    'n_estimators': [50,90,120],\n","    'max_depth' : [8,9,10],\n","}\n","\n","grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=3)\n","\n","grid.fit(scaled_train1, y_train1)\n","print(f\"'FD001' : {grid.best_score_ , grid.best_params_}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Fitting the model\n","\n","rf=RandomForestRegressor(n_estimators=120,  max_depth=10, n_jobs=-1, random_state=42)\n","rf.fit(scaled_train1, y_train1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Random-Forest-Regressor on FD001-test dataset:\\n\")\n","prediction(rf, scaled_test1, y_test1)\n","\n","print(f\"\\nRandom-Forest-Regressor on FD001-train dataset:\\n\")\n","prediction(rf, scaled_train1, y_train1)\n","\n","print(f\"\\nRandom-Forest-Regressor on FD001-validation dataset:\\n\")\n","rf_y_pred1=prediction(rf, scaled_X_valid1, rul1)\n","\n","rf_rul1=rul1.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(rf_rul1, rf_y_pred1)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD002'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=3)\n","\n","grid.fit(scaled_train2, y_train2)\n","print(f\"'FD002' : {grid.best_score_ , grid.best_params_}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Fitting the model\n","\n","rf=RandomForestRegressor(n_estimators=90,  max_depth=10, n_jobs=-1, random_state=42)\n","rf.fit(scaled_train2, y_train2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Random-Forest-Regressor on FD002-test dataset:\\n\")\n","prediction(rf, scaled_test2, y_test2)\n","\n","print(f\"\\nRandom-Forest-Regressor on FD002-train dataset:\\n\")\n","prediction(rf, scaled_train2, y_train2)\n","\n","print(f\"\\nRandom-Forest-Regressor on FD002-validation dataset:\\n\")\n","rf_y_pred2=prediction(rf, scaled_X_valid2, rul2)\n","\n","rf_rul2=rul2.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(rf_rul2, rf_y_pred2)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD003'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=3)\n","\n","grid.fit(scaled_train3, y_train3)\n","print(f\"'FD002' : {grid.best_score_ , grid.best_params_}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Fitting the model\n","\n","rf=RandomForestRegressor(n_estimators=120,  max_depth=10, n_jobs=-1, random_state=42)\n","rf.fit(scaled_train3, y_train3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Random-Forest-Regressor on FD003-test dataset:\\n\")\n","prediction(rf, scaled_test3, y_test3)\n","\n","print(f\"\\nRandom-Forest-Regressor on FD003-train dataset:\\n\")\n","prediction(rf, scaled_train3, y_train3)\n","\n","print(f\"\\nRandom-Forest-Regressor on FD003-validation dataset:\\n\")\n","rf_y_pred3=prediction(rf, scaled_X_valid3, rul3)\n","\n","rf_rul3=rul3.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(rf_rul3, rf_y_pred3)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD004'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["grid = GridSearchCV(estimator, param_grid, n_jobs=-1, cv=3)\n","\n","grid.fit(scaled_train4, y_train4)\n","print(f\"'FD002' : {grid.best_score_ , grid.best_params_}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## Fitting the model\n","\n","rf=RandomForestRegressor(n_estimators=120,  max_depth=10, n_jobs=-1, random_state=42)\n","rf.fit(scaled_train4, y_train4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Random-Forest-Regressor on FD004-test dataset:\\n\")\n","prediction(rf, scaled_test4, y_test4)\n","\n","print(f\"\\nRandom-Forest-Regressor on FD004-train dataset:\\n\")\n","prediction(rf, scaled_train4, y_train4)\n","\n","print(f\"\\nRandom-Forest-Regressor on FD004-validation dataset:\\n\")\n","rf_y_pred4=prediction(rf, scaled_X_valid4, rul4)\n","\n","rf_rul4=rul4.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(rf_rul4, rf_y_pred4)"]},{"cell_type":"markdown","metadata":{},"source":["## 5. Support Vector Regressor"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD001'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.svm import SVR\n","\n","svr = SVR(kernel = 'rbf')\n","svr.fit(scaled_train1, y_train1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Support-Vector-Regressor on FD001-test dataset:\\n\")\n","prediction(svr, scaled_test1, y_test1)\n","\n","print(f\"\\nSupport-Vector-Regressor on FD001-train dataset:\\n\")\n","prediction(svr, scaled_train1, y_train1)\n","\n","print(f\"\\nSupport-Vector-Regressor on FD001-validation dataset:\\n\")\n","svr_y_pred1=prediction(svr, scaled_X_valid1, rul1)\n","\n","svr_rul1=rul1.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(svr_rul1, svr_y_pred1)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD002'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["svr.fit(scaled_train2, y_train2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Support-Vector-Regressor on FD002-test dataset:\\n\")\n","prediction(svr, scaled_test2, y_test2)\n","\n","print(f\"\\nSupport-Vector-Regressor on FD002-train dataset:\\n\")\n","prediction(svr, scaled_train2, y_train2)\n","\n","print(f\"\\nSupport-Vector-Regressor on FD002-validation dataset:\\n\")\n","svr_y_pred2=prediction(svr, scaled_X_valid2, rul2)\n","\n","svr_rul2=rul2.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(svr_rul2, svr_y_pred2)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD003'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["svr.fit(scaled_train3, y_train3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Support-Vector-Regressor on FD003-test dataset:\\n\")\n","prediction(svr, scaled_test3, y_test3)\n","\n","print(f\"\\nSupport-Vector-Regressor on FD003-train dataset:\\n\")\n","prediction(svr, scaled_train3, y_train3)\n","\n","print(f\"\\nSupport-Vector-Regressor on FD003-validation dataset:\\n\")\n","svr_y_pred3=prediction(svr, scaled_X_valid3, rul3)\n","\n","svr_rul3=rul3.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(svr_rul3, svr_y_pred3)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD004'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["svr.fit(scaled_train4, y_train4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"Support-Vector-Regressor on FD004-test dataset:\\n\")\n","prediction(svr, scaled_test4, y_test4)\n","\n","print(f\"\\nSupport-Vector-Regressor on FD004-train dataset:\\n\")\n","prediction(svr, scaled_train4, y_train4)\n","\n","print(f\"\\nSupport-Vector-Regressor on FD004-validation dataset:\\n\")\n","svr_y_pred4=prediction(svr, scaled_X_valid4, rul4)\n","\n","svr_rul4=rul4.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(svr_rul4, svr_y_pred4)"]},{"cell_type":"markdown","metadata":{},"source":["## 6. XG-Boost Regressor"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD001'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from xgboost import XGBRegressor\n","xgbr=XGBRegressor(objective ='reg:squarederror', colsample_bytree = 0.3, learning_rate = 0.1,\n","                          max_depth = 5, alpha = 10, n_estimators = 100)\n","xgbr.fit(scaled_train1, y_train1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"XG-Boost-Regressor on FD001-test dataset:\\n\")\n","prediction(xgbr, scaled_test1, y_test1)\n","\n","print(f\"\\nXG-Boost-Regressor on FD001-train dataset:\\n\")\n","prediction(xgbr, scaled_train1, y_train1)\n","\n","print(f\"\\nXG-Boost-Regressor on FD001-validation dataset:\\n\")\n","xgbr_y_pred1=prediction(xgbr, scaled_X_valid1, rul1)\n","\n","xgbr_rul1=rul1.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(xgbr_rul1, xgbr_y_pred1)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD002'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["xgbr.fit(scaled_train2, y_train2)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"XG-Boost-Regressor on FD002-test dataset:\\n\")\n","prediction(xgbr, scaled_test2, y_test2)\n","\n","print(f\"\\nXG-Boost-Regressor on FD002-train dataset:\\n\")\n","prediction(xgbr, scaled_train2, y_train2)\n","\n","print(f\"\\nXG-Boost-Regressor on FD002-validation dataset:\\n\")\n","xgbr_y_pred2=prediction(xgbr, scaled_X_valid2, rul2)\n","\n","xgbr_rul2=rul2.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(xgbr_rul2, xgbr_y_pred2)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD003'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["xgbr.fit(scaled_train3, y_train3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"XG-Boost-Regressor on FD003-test dataset:\\n\")\n","prediction(xgbr, scaled_test3, y_test3)\n","\n","print(f\"\\nXG-Boost-Regressor on FD003-train dataset:\\n\")\n","prediction(xgbr, scaled_train3, y_train3)\n","\n","print(f\"\\nXG-Boost-Regressor on FD003-validation dataset:\\n\")\n","xgbr_y_pred3=prediction(xgbr, scaled_X_valid3, rul3)\n","\n","xgbr_rul3=rul3.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(xgbr_rul3, xgbr_y_pred3)"]},{"cell_type":"markdown","metadata":{},"source":["#### 'FD004'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["xgbr.fit(scaled_train4, y_train4)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["## predict and evaluate\n","\n","print(f\"XG-Boost-Regressor on FD004-test dataset:\\n\")\n","prediction(xgbr, scaled_test4, y_test4)\n","\n","print(f\"\\nXG-Boost-Regressor on FD004-train dataset:\\n\")\n","prediction(xgbr, scaled_train4, y_train4)\n","\n","print(f\"\\nXG-Boost-Regressor on FD004-validation dataset:\\n\")\n","xgbr_y_pred4=prediction(xgbr, scaled_X_valid4, rul4)\n","\n","xgbr_rul4=rul4.copy()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plot_predActual(xgbr_rul4, xgbr_y_pred4)"]},{"cell_type":"markdown","metadata":{},"source":["# Comparing Models to find out the best Model for RUL prediction."]},{"cell_type":"markdown","metadata":{},"source":["## 1. Comparison of Models for FD001."]},{"cell_type":"markdown","metadata":{},"source":["linear\n","\n","MSE: 2041.0287778421045\n","RMSE: 45.17774648919648\n","R-squared: 0.5532676072910516\n","MAE: 34.576452557241765\n","\n","\n","ridge\n","\n","MSE: 2039.6193242550423\n","RMSE: 45.162144814601554\n","R-squared: 0.5535761029772449\n","MAE: 34.55331983469118\n","\n","lasso\n","\n","MSE: 2040.9764506111428\n","RMSE: 45.17716735931042\n","R-squared: 0.5532790604706174\n","MAE: 34.57615181929818\n","\n","rf\n","\n","MSE: 1784.3600787346606\n","RMSE: 42.24168650438404\n","R-squared: 0.609446247852401\n","MAE: 29.828273708727632\n","\n","svr\n","\n","MSE: 2078.365958984826\n","RMSE: 45.58909912451469\n","R-squared: 0.5450953911763283\n","MAE: 32.11046269923975\n","\n","xgb\n","\n","MSE: 1819.7593833704395\n","RMSE: 42.65863785179315\n","R-squared: 0.6016981865649487\n","MAE: 30.42753632481837"]},{"cell_type":"markdown","metadata":{},"source":["## Observation : Out of all Models Random-Forest-Regressor-Model is performing best for 'FD001'."]},{"cell_type":"markdown","metadata":{},"source":["## 2. Comparison of Models for FD002."]},{"cell_type":"markdown","metadata":{},"source":["linear\n","\n","MSE: 2302.01347765385\n","RMSE: 47.979302596576474\n","R-squared: 0.509454651526867\n","MAE: 35.580024537978105\n","\n","\n","ridge\n","\n","MSE: 2303.3231245738834\n","RMSE: 47.992948696385426\n","R-squared: 0.5091755735757599\n","MAE: 35.58746746415166\n","\n","lasso\n","\n","MSE: 2214.351109312519\n","RMSE: 47.056892261522314\n","R-squared: 0.5281349796150436\n","MAE: 35.33742029451255\n","\n","rf\n","\n","MSE: 2832.8931321431423\n","RMSE: 53.224929611443756\n","R-squared: 0.3963273620315162\n","MAE: 36.9876323754922\n","\n","svr\n","\n","MSE: 3897.987400617866\n","RMSE: 62.43386421340478\n","R-squared: 0.1693621230537824\n","MAE: 48.90579882032297\n","\n","xgb\n","\n","MSE: 2609.663689599478\n","RMSE: 51.08486752062178\n","R-squared: 0.4438962254395832\n","MAE: 35.62026525634939\n"]},{"cell_type":"markdown","metadata":{},"source":["## Observation : Out of all Models Lasso-Regression-Model is performing best for 'FD002'."]},{"cell_type":"markdown","metadata":{},"source":["## 3.Comparison of Models for FD003."]},{"cell_type":"markdown","metadata":{},"source":["linear\n","\n","MSE: 3998.3168350205747\n","RMSE: 63.23224521571707\n","R-squared: 0.5920341249143768\n","MAE: 46.75689186037759\n","\n","ridge\n","\n","MSE: 3997.194445109598\n","RMSE: 63.223369453941615\n","R-squared: 0.5921486472999486\n","MAE: 46.760350670556626\n","\n","lasso\n","\n","MSE: 3995.5456516168438\n","RMSE: 63.210328678285194\n","R-squared: 0.5923168809612271\n","MAE: 46.77220057311553\n","\n","rf\n","\n","MSE: 3563.9708588467397\n","RMSE: 59.69900215955657\n","R-squared: 0.6363523577036414\n","MAE: 41.51834669896903\n","\n","svr\n","\n","MSE: 3950.0340940443707\n","RMSE: 62.849296686950844\n","R-squared: 0.5969606256112101\n","MAE: 41.54825831645149\n","\n","xgb\n","\n","MSE: 3515.4085264917385\n","RMSE: 59.290880635151126\n","R-squared: 0.6413073863401615\n","MAE: 40.60723399045398"]},{"cell_type":"markdown","metadata":{},"source":["## Observation : Out of all Models XG-Boost-Regressor-Model is performing best for 'FD003'."]},{"cell_type":"markdown","metadata":{},"source":["## 4.Comparison of Models for FD004."]},{"cell_type":"markdown","metadata":{},"source":["linear\n","\n","MSE: 3776.2469063177487\n","RMSE: 61.451174979147055\n","R-squared: 0.5303442740239465\n","MAE: 46.125163638386255\n","\n","\n","ridge\n","\n","MSE: 3776.2474423021395\n","RMSE: 61.451179340205826\n","R-squared: 0.5303442073630145\n","MAE: 46.12516376638492\n","\n","lasso\n","\n","MSE: 4517.4482640797105\n","RMSE: 67.21196518537239\n","R-squared: 0.4381602960134685\n","MAE: 50.714499800227586\n","\n","rf\n","\n","MSE: 4204.228456755979\n","RMSE: 64.84002202926816\n","R-squared: 0.4771157667885907\n","MAE: 46.09589704437344\n","\n","svr\n","\n","MSE: 6648.0981434585865\n","RMSE: 81.53587028700059\n","R-squared: 0.17316917103529783\n","MAE: 61.97958108597923\n","\n","xgb\n","\n","MSE: 4054.6415441286626\n","RMSE: 63.676067279070104\n","R-squared: 0.49572004553131854\n","MAE: 44.93002025586017\n"]},{"cell_type":"markdown","metadata":{},"source":["## Observation : Out of all Models Ridge-Regression-Model is performing best for 'FD004'."]},{"cell_type":"markdown","metadata":{},"source":["### Pickle File to Scale the new input data for furthur use."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pickle\n","pickle.dump(scaler,open(\"scaler.pkl\",\"wb\"))"]},{"cell_type":"markdown","metadata":{},"source":["### Pickle File of Random-Forest-Regressor-Model for 'FD001' for new input data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pickle.dump(rf,open(\"random-forest(FD001).pkl\",\"wb\"))"]},{"cell_type":"markdown","metadata":{},"source":["### Pickle File of Lasso-Regression-Model for 'FD002' for new input data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pickle.dump(lasso,open(\"lasso(FD002).pkl\",\"wb\"))"]},{"cell_type":"markdown","metadata":{},"source":["### Pickle File of XG-Boost-Regressor-Model for 'FD003' for new input data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pickle.dump(xgbr,open(\"xgbr(FD003).pkl\",\"wb\"))"]},{"cell_type":"markdown","metadata":{},"source":["### Pickle File of Ridge-Regression-Model  for 'FD004' for new input data."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["pickle.dump(ridge,open(\"ridge(FD004).pkl\",\"wb\"))"]},{"cell_type":"markdown","metadata":{},"source":["By Yash on 31 December 2023.\n","\n","linkedin profile: \n","https://www.linkedin.com/in/yashh2417?lipi=urn%3Ali%3Apage%3Ad_flagship3_profile_view_base_contact_details%3BW9Fb0etwRhSHzAYIHwO5CQ%3D%3D\n","\n","github link:\n","https://github.com/yashh2417/c-mapss\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":276801,"sourceId":572434,"sourceType":"datasetVersion"}],"dockerImageVersionId":30626,"isGpuEnabled":false,"isInternetEnabled":false,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
